{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "# importing the csv files to respective dataframes\n",
    "df = pd.read_csv(\"C:/MachineLearning/Digit_Recognition/train.csv\")\n",
    "df2 = pd.read_csv('C:/MachineLearning/Digit_Recognition/test_data.csv')\n",
    "df3 =pd.read_csv('C:/MachineLearning/Digit_Recognition/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to assign the weights\n",
    "def initialize_network(n_inputs, n_hidden, n_output):\n",
    "#     between input and hidden layer\n",
    "    hidden_layer = np.array([[random() * 0.01 for i in range(n_inputs + 1)] for i in range(n_hidden)])\n",
    "#     between hidden layer and output \n",
    "    output_layer = np.array([[random() * 0.01 for i in range(n_hidden + 1)] for i in range(n_output)])\n",
    "    return(hidden_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing the weights , using 500 hidden neurons\n",
    "weights = initialize_network(784,500,10)\n",
    "hidden_weights = weights[0]\n",
    "output_weights = weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transfer neuron activation\n",
    "def sigmoid(out_hidden):\n",
    "    return 1.0/(1.0 + np.exp(-out_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward_propagation\n",
    "def forward_propagate(weights, weights1, input):\n",
    "    out_hidden = np.dot(weights, input)\n",
    "    out_inputs = sigmoid(out_hidden)\n",
    "#   adding the input for bias in output layer\n",
    "    out_inputs_b = np.concatenate((out_inputs,[[1]]),0)\n",
    "    inputs_out = np.dot(weights1, out_inputs_b)  \n",
    "    output = sigmoid(inputs_out)\n",
    "    return (output, out_inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the derivative of output neuron\n",
    "def deri_output(output, expected):\n",
    "    transf1 = output * (1 - output)\n",
    "    transf = transf1 * (expected - output)\n",
    "    return transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating error\n",
    "def backward_propagate_error( weights1, output, out_hidden, expected):\n",
    "    error = deri_output(output,expected)\n",
    "    error_hid_int = weights1 *error\n",
    "    error_hid_sum = np.sum(error_hid_int, 0)\n",
    "    error_hid_sum_mat = np.array([error_hid_sum])    \n",
    "    out_hidden_int = out_hidden * (1 - out_hidden)\n",
    "    error_hidden = error_hid_sum_mat.T * out_hidden_int\n",
    "    return (error, error_hidden)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Updating the weights\n",
    "def update_weight (weight, weight1, l_rate, out_error, hid_error, out_hidden1, input1):\n",
    "    update_w_out_int = np.dot(out_hidden1,out_error.T)\n",
    "    update_w_out_trans = update_w_out_int.T\n",
    "    update_w_out_l = l_rate * update_w_out_trans\n",
    "    update_w_out = weight1 + update_w_out_l\n",
    "    update_w_hid_int = np.dot(input1,hid_error.T )\n",
    "    update_w_hid_trans = update_w_hid_int.T\n",
    "    update_w_hid_l = l_rate * update_w_hid_trans\n",
    "    update_w_hid = weight + update_w_hid_l\n",
    "    return (update_w_out, update_w_hid)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# array for expected outputs\n",
    "expect_out = np.array(np.diag(np.ones(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "error = list()\n",
    "# running the iterations for 10 times (10 epochs)\n",
    "for j in range(15):\n",
    "    error_sum = 0\n",
    "#   iterating through each row \n",
    "    for keys,row in df.iterrows():\n",
    "#     formatting the train data according to the weight matrix's dimension\n",
    "        label = row.iloc[0]\n",
    "        input1 = row.iloc[1:]\n",
    "#     Scaling the training data\n",
    "        input2 = np.array([input1])/255\n",
    "        input3 = input2.T    \n",
    "        input4 = np.concatenate((input3,[[1]]),0)\n",
    "#     calling the forward propagation \n",
    "        forward_out = forward_propagate(hidden_weights, output_weights, input4)\n",
    "#     assigning the ouput from output neurons\n",
    "        out_hidden = forward_out[1]\n",
    "#     assigning the output from hidden neurons\n",
    "        output = forward_out[0]\n",
    "#     assigning the ouput according to the label of the tain data\n",
    "        expect_mat = expect_out[label] \n",
    "        expected_output = np.array([expect_mat]).T\n",
    "#     calculating the total error for each row\n",
    "        error_one_row = ((expected_output - output)**2)/2\n",
    "#     adding the erorrs to find the total error of one epoch\n",
    "        error_sum += error_one_row\n",
    "#     formatting the weights(removing the bias weight for backward propagation)\n",
    "        numcol = len(output_weights[0])\n",
    "        output_weights1 = np.delete(output_weights, numcol - 1, 1)\n",
    "#     calulating the errors after backward propagation\n",
    "        errors_p = backward_propagate_error(output_weights1, output, out_hidden, expected_output)\n",
    "#     assigning the output error and hidden error\n",
    "        out_error = errors_p[0]\n",
    "        hid_error = errors_p[1]\n",
    "#     formatting the hidden layer ouputs(for bias)\n",
    "        out_hidden1 =  np.concatenate((out_hidden,[[1]]),0)\n",
    "#     learning rate\n",
    "        l_rate = 0.5\n",
    "#     updating the weights\n",
    "        update_weight_one = update_weight(hidden_weights, output_weights, l_rate, out_error, hid_error, out_hidden1, input4)\n",
    "# assigning the updated weights\n",
    "        output_weights = update_weight_one[0]\n",
    "        hidden_weights = update_weight_one[1]\n",
    "# adding the total error of network after one network to the list\n",
    "    error.append(error_sum)\n",
    "# shuffling the training data\n",
    "    df = df.sample(frac=1)\n",
    "    print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_all =list()\n",
    "for key, layer in enumerate(error):\n",
    "    err= np.sum(error[key])/40000\n",
    "    error_all.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxKFvZpYhDn0zswz5/5Bcfo5JsfnDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28a7e4a6710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the errors of network during training\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(error_all)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passing the test data into the network\n",
    "pos_max = list()\n",
    "for keys,row in df2.iterrows():\n",
    "    data = row.iloc[0:]\n",
    "    data2 = np.array([data])/255\n",
    "    data3 = data2.T    \n",
    "    data4 = np.concatenate((data3,[[1]]),0)\n",
    "    forward_out = forward_propagate(hidden_weights, output_weights, data4)\n",
    "    output = forward_out[0]\n",
    "# finding the position of the maximum output in the list\n",
    "    pos_max_int = np.argmax(output)\n",
    "    pos_max.append(pos_max_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting into matrix form\n",
    "pos_max_mat = np.array([pos_max])\n",
    "pos_max_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the labels of label_test\n",
    "label_test = np.array(df3).T\n",
    "label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97299999999999998"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing the output with the label\n",
    "comparison = np.equal(pos_max_mat, label_test)\n",
    "np.sum(comparison)/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
